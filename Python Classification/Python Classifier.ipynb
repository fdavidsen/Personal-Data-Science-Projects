{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this mini-project is to gain experience with natural language processing and use text data to train a machine learning model to make a classification. For this mini-project, I will be working with 4 articles from Wikipedia. There are 3 articles for python the snake because they are short comparing to the article for python the programming language. The objective is to train a model to classify whether a sentence is referring to python the snake or python the programming language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus is taken from Wikipedia articles and comes as a page of each article. To load the page into proper documents format, I will need to use the spacy library and transform each page into a list of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text processing pipeline.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Return a list of sentences in Wikipedia articles.\n",
    "def pages_to_sentences(*pages):\n",
    "    sentences = []\n",
    "    \n",
    "    for page in pages:\n",
    "        p = wikipedia.page(page)\n",
    "        doc = nlp(p.content)\n",
    "        sentences += [sent.text for sent in doc.sents]\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_sents = pages_to_sentences('Reticulated Python', 'Ball Python', 'Pythonidae')\n",
    "language_sents = pages_to_sentences('Python (programming language)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the list of sentences is created, I will concatenate them as a complete set of documents. I will manually create the labels by multiplying each class with the length of respective documents and concatenate them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = animal_sents + language_sents\n",
    "labels = (['animal'] * len(animal_sents)) + (['language'] * len(language_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I construct a machine learning model trained on a normalized raw counts algorithm that performs tf-idf weighting on the counts. Here are some things to consider:\n",
    "* Consider some hyperparameters to tune for the model.\n",
    "* Subsampling the training data will boost training times, which helpful when determining the best hyperparameters to use. Note, the final model will perform best if it is trained on the full data set.\n",
    "* Including stop words may help with performance.\n",
    "* Include bigram may help with performance but the risk of overfitting will increase.\n",
    "* More documents will lead to better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are many symbols in the documents, these symbols will not give any signal to the model. I decided to add those symbols to the stop words, so they will not be interpreted as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = {'\\n', '\\n\\n', '\\n\\n\\n', ' ', '\"', \"'\", \"'s\", '(', ')', ',', '-', '.', ':', ';', '<', '='}\n",
    "evolved_stop_words = STOP_WORDS.union(symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use MultinomialNB model because it will give me the probability value of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training accuracy: 0.8971028971028971'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=evolved_stop_words, ngram_range=(1,2))),\n",
    "    ('classifier', GridSearchCV(MultinomialNB(), param_grid={'alpha': np.linspace(1, 100, 100)}))\n",
    "])\n",
    "est.fit(documents, labels)\n",
    "\n",
    "'Training accuracy: {}'.format(est.score(documents, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blah blah', 'blah eggs', 'blah evaluates', 'blender', 'blender cinema']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.named_steps['vectorizer'].get_feature_names()[1000:1005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some testing documents that may trick the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs = [\"My Python program is only 100 bytes long.\",\n",
    "             \"A python's bite is not venomous but still hurts.\",\n",
    "             \"I can't find the error in the python code.\",\n",
    "             \"Where is my pet python; I can't find her!\",\n",
    "             \"I use for and while loops when writing Python.\",\n",
    "             \"The python will loop and wrap itself onto me.\",\n",
    "             \"I use snake case for naming my variables.\",\n",
    "             \"My python has grown to over 10 ft long!\",\n",
    "             \"I use virtual environments to manage package versions.\",\n",
    "             \"Pythons are the largest snakes in the environment.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['animal', 'language'], dtype='<U8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Python program is only 100 bytes long. --> language at 66.8501%\n",
      "A python's bite is not venomous but still hurts. --> animal at 64.9406%\n",
      "I can't find the error in the python code. --> language at 83.0824%\n",
      "Where is my pet python; I can't find her! --> animal at 73.6011%\n",
      "I use for and while loops when writing Python. --> language at 63.5988%\n",
      "The python will loop and wrap itself onto me. --> language at 65.4708%\n",
      "I use snake case for naming my variables. --> animal at 51.8593%\n",
      "My python has grown to over 10 ft long! --> animal at 73.6018%\n",
      "I use virtual environments to manage package versions. --> language at 75.1641%\n",
      "Pythons are the largest snakes in the environment. --> animal at 91.4915%\n"
     ]
    }
   ],
   "source": [
    "y_proba = est.predict_proba(test_docs)\n",
    "predicted_indices = (y_proba[:, 1] > 0.5).astype(int)\n",
    "\n",
    "for i, index in enumerate(predicted_indices):\n",
    "    print(test_docs[i], '--> {} at {:g}%'.format(est.classes_[index], y_proba[i, index] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model did a good job with the test document unless it failed with the sentence \"The python will loop and wrap itself onto me.\", but it is not so poor because it is only sure on around 65%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
